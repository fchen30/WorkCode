import requests
import os
from requests_kerberos import HTTPKerberosAuth, OPTIONAL
import pandas as pd
from bs4 import BeautifulSoup
from selenium import webdriver
import copy
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.by import By
import time

#Prius
import datetime
now = datetime.datetime.now()
#FCs = ['ABE2','ABE3','ABE4','ABE8','ATL7','ATL8','ATL9','AVP1','AVP3','BDL1',
#    'BDL2','BFI1','BFI3','BFI4','BFI6','BFI7','BFIX','BNA1','BNA2','BNA3',
#    'BOS6','BOS7','BWI2','BWI6','CAE1','CAE3','CHA1','CHA2','CLT2','CMH1',
#    'CMH2','CVG1','CVG2','CVG3','CVG7','DAL6','DEN2','DEN6','DET1','DFW6',
#    'DFW7','DFW9','EWR4','EWR6','EWR7','EWR9','FTW1','FTW2','GSP1','HCA6',
#    'HIL2','HOU2','HTX2','HWA3','IND1','IND2','IND3','IND4','IND5','IVSA',
#    'IVSB','JAX2','JAX3','LAS6','LAX6','LEX1','LEX2','LGA6','LGB4','LGB6',
#    'LGB8','MCI7','MDT1','MDT2','MDW2','MDW4','MDW6','MDW7','MDW8','MDW9',
#    'MGE1','MGE3','MIA6','MKC4','MKC6','MKE1','MSP1','OAK3','OAK4','OAK6',
#    'OAK7','ONT2','ONT4','ONT6','ONT7','ONT8','ONT9','ORD6','PHL1','PHL3',
#    'PHL4','PHL5','PHL6','PHL7','PHX3','PHX5','PHX6','PHX7','PHX9','PIN1',
#    'POH1','PWA1','RIC1','RIC2','RNO1','RNO4','SAT1','SAT2','SDF1','SDF2',
#    'SDF4','SDF6','SDF8','SDF9','SEA8','SJC7','SMF1','SNA4','STL4','STL6',
#    'TEB3','TEB6','TPA1','TPA2','TUL1','UAZ1','UCA1','UCA7','UCA8','UCA9',
#    'UFL1','UGA2','UIL1','UIN1','UMD1','UMN1','UNV1','UOR1','UTN1','UTX1',
#    'UTX2','UTX3','UTX5','UVA1','UVA2','UVA3','UWA1','UWA2','VUGF','VUK1',
#    'VUKD','VUKE','VUKF','VUKG','VUKH','VUKI','VUKJ','VUTD','XBC1','XIX2',
#    'XSP1','XUSB','XUSC','XUSD','XUSE','XUSF','XUSG','XUSH','XUSJ','XUSK',
#    'XUSM','XUSN','XUSO']

FCs = [
#IXD
'ABE8','AVP1','CLT2','CVG3','FTW1','LGB8','MDW2','ONT8',
#Sort Traditional
'ABE2','CAE1','CHA1','IND1','LEX1','MDW4','MGE1','ONT2',
'ONT6','PHL1','PHL7','PHX6','RIC2','STL6',
#Sort AR
'BDL2','BFI1','BFI4','BFIX','BWI2','CMH1','DFW7','EWR4',
'EWR9','HOU2','JAX2','MDW7','MKC6','MKE1','MSP1','OAK4',
'SAT2','SMF1','TPA1',
#Sort Supplemental
'ATL7','PHX9',
#Speciality
'ABE3','BNA3','CVG1','IND4','MDT2','PHX3','SDF1','SDF4',
'SDF6','SDF8',
#Nonsort Traditional
'ABE4','BNA2','BOS7','CHA2','CMH2','DEN2','DET1','GSP1',
'IND2','IND5','JAX3','LAS6','LGB4','MDT1','MDW6','MDW9',
'MGE3','MKC4','ONT9','PHL4','PHL5','PHL6','PHX5','PHX7',
'RIC1','RNO4','SJC7','SNA4','STL4','TEB3','TEB6',
#Nonsort AR
'BFI3','DFW6','OAK3','SAT1','TPA2',
#3PL
'XUSB','XUSC','XUSD','XUSE','XUSF','XUSH','XUSJ','XUSK',
'XUSM',
#Special Handling
'ATL8','AVP3','BFI7','FTW2','MDW8'
]
cert = r"C:\Users\chenfa\Documents\YardLog\cacerts.pem"
os.environ["REQUESTS_CA_BUNDLE"] = cert
kerberos = HTTPKerberosAuth(mutual_authentication=OPTIONAL)
#prius = open('prius_data2.txt','w')
def prius(FCs):
    table = []
    for FC in FCs:
        url = 'https://inbound.com/appt_outlook?utf8=%E2%9C%93&fc='+FC+'&org=US&commit=Update'

        session = requests.Session()
        request = session.get(url, auth=kerberos).content.decode("latin-1")
        soup = BeautifulSoup(request,"lxml")
        s = soup.find('tfoot')

        #headers = [header.text for header in s[2].find_all('th')]



        rows = ([val.text for val in s.find_all('td')]) #.encode('utf8')
        #srows[i].append([row.find_all('td')[-1].contents[2]])


        if rows[0] == 'Total':
            rows[0] = FC
            print(datetime.datetime.now() - now,rows)
            table.append(rows)

    prius = pd.DataFrame(table)
    prius.to_csv('C:pruis.csv', index = False, header = None )

# prius(FCs)

# WTP
# cert = r"C:\Users\chenfa\Documents\YardLog\cacerts.pem"
# os.environ["REQUESTS_CA_BUNDLE"] = cert
# kerberos_auth = HTTPKerberosAuth(mutual_authentication=OPTIONAL)

def wtp():
    r = requests.get('https://noc.corp.amazon.com/data/wtp_live.csv?', verify=cert, auth=kerberos)
    data = r.text

    import sys


    if sys.version_info[0] < 3:
        from StringIO import StringIO
    else:
        from io import StringIO

    data = StringIO(data)

    df = pd.read_csv(data, sep=",")
    wtp = df.loc[:, 'source':'Business_Type_Filter']
    wtp.to_csv(r'C:\wtp.csv', index=False)

# wtp()
# CU and BG


url = [["bg", "https://ipc-bm.com/inbound/inbound/view_transpose?org=US&report_id="],
       ["bgca", "https://ipc-bm.com/inbound/inbound/view_transpose?org=CA&report_id="],
       ["cu", "https://capacity.com/sccp/101/storage_requirement_metric"],
       ["cuca", "https://capacity.com/sccp/115/storage_requirement_metric"]]


def read(html):
    html_soup = BeautifulSoup(html, 'lxml')
    tables = []
    table_div = html_soup.find('div', {'id': 'container'})
    # table = table_div.findAll("table")[]
    tables_html = table_div.find_all("table", {'class': 'GG3VN1MDCD table-bordered'})
    # Parse each table
    for n in range(0, len(tables_html)):

        n_cols = 0
        n_rows = 0

        for row in tables_html[n].find_all("tr"):
            col_tags = row.find_all(["td", "th"])
            if len(col_tags) > 0:
                n_rows += 1
                if len(col_tags) > n_cols:
                    n_cols = len(col_tags)

        # Create dataframe
        df = pd.DataFrame(index=range(0, n_rows), columns=range(0, n_cols))

        skip_index = [0 for i in range(0, n_cols)]
        # Create list to store rowspan values

        # Start by iterating over each row in this table...
        row_counter = 0
        for row in tables_html[n].find_all("tr"):

            # Skip row if it's blank
            if len(row.find_all(["td", "th"])) == 0:
                next()

            else:

                # Get all cells containing data in this row
                columns = row.find_all(["td", "th"])
                col_dim = []
                row_dim = []
                col_dim_counter = -1
                row_dim_counter = -1
                col_counter = -1
                this_skip_index = copy.deepcopy(skip_index)

                for col in columns:

                    # Determine cell dimensions
                    colspan = col.get("colspan")
                    if colspan is None:
                        col_dim.append(1)
                    else:
                        col_dim.append(int(colspan))
                    col_dim_counter += 1

                    rowspan = col.get("rowspan")
                    if rowspan is None:
                        row_dim.append(1)
                    else:
                        row_dim.append(int(rowspan))
                    row_dim_counter += 1

                    # Adjust column counter
                    if col_counter == -1:
                        col_counter = 0
                    else:
                        col_counter = col_counter + col_dim[col_dim_counter - 1]

                    while skip_index[col_counter] > 0:
                        col_counter += 1

                    # Get cell contents
                    cell_data = col.get_text()

                    # Insert data into cell
                    df.iat[row_counter, col_counter] = cell_data

                    # Record column skipping index
                    if row_dim[row_dim_counter] > 1:
                        this_skip_index[col_counter] = row_dim[row_dim_counter]

            # Adjust row counter
            row_counter += 1

            # Adjust column skipping index
            skip_index = [i - 1 if i > 0 else i for i in this_skip_index]

        # Append dataframe to list of tables
        tables.append(df)

    return (tables)


def read_web(webbook):
    driver = webdriver.Chrome(r'C:\chromedriver')
    
    def read_bg(url):
        driver.get(url[1])
        WebDriverWait(driver, 50).until(EC.visibility_of_all_elements_located((By.ID, "inbound/inbound-view_transpose")))
        html = (driver.execute_script("return document.getElementsByTagName('html')[0].innerHTML"))
        soup = BeautifulSoup(html, 'lxml')
        table = soup.find('table', {'class': 'table table-condensed table-hover table-report'})

        for body in table('tbody'):
            body.unwrap()

        df = pd.read_html(str(table), flavor="bs4")
        df = pd.DataFrame(df[0])
        df.to_csv('C:\\Users\\chenfa\\Documents\\YardLog\\' + url[0] + '.csv', index=False)

    def read_cu(url):
        driver.get(url[1])
        wait = WebDriverWait(driver, 50)
        wait.until(EC.element_to_be_clickable((By.ID, "show_real_time_inventory_checkbox"))).click()
        driver.find_element_by_xpath("//input[@value ='Table']").click()
        WebDriverWait(driver, 50).until(EC.presence_of_element_located((By.ID, "CPMetricTableNONSORTABLE")))
        html = (driver.execute_script("return document.getElementsByTagName('html')[0].innerHTML"))
        x = read(html)
        df = pd.concat(x)
        df.to_csv('C:\\\' + url[0] + '.csv', index=False)

    for i in webbook:
        if i[0].startswith('bg'):
            read_bg(i)
        elif i[0].startswith('cu'):
            read_cu(i)
    driver.quit()







# read_web(url)
# from xlwings import Book

def autofill():
    # wb = Book.caller()
    prius(FCs)
    wtp()
    read_web(url)
    
autofill()

import smtplib
from email.mime.multipart import MIMEMultipart
from email.mime.base import MIMEBase
from email.mime.text import MIMEText
from email.utils import formatdate
from email import encoders
import tkinter
import tkinter.simpledialog

import xlwings as xw

#Your user ID
#def get_user():    
#    tk_root = tkinter.Tk()
#    tk_root.withdraw()
#    return tkinter.simpledialog.askstring('UserName','What is your user name(your amazon email address)?')
#
##Your password
#def get_pass():
#    tk_root = tkinter.Tk()
#    tk_root.withdraw()
#    return tkinter.simpledialog.askstring('Password','What is your amazon password?', show='*')
#
##Who you want to send 
#def get_destination():
#    tk_root = tkinter.Tk()
#    tk_root.withdraw()
#    return tkinter.simpledialog.askstring('Destination','Who do you want to send the report to? (Full email address)')

def send_mail(isTls=True):
    send_from = ""
    password = ""

#    send_to = get_destination()
    #Email List for who will receive the alert 
    send_to = ['@amazon.com','@amazon.com','@amazon.com']
    msg = MIMEMultipart()
    msg['From'] = send_from
    msg['To'] = '@amazon.com'
    msg['Date'] = formatdate(localtime = True)
    msg['Subject'] = 'Yard Backlog Report - '+str(datetime.datetime.now().hour)+'00PST'
    wb = xw.Book(r'C:\Akash_Report_Macro_US_CAUpdate1.21.xlsm')
    sht = wb.sheets['metric - current']
    transbacklog = sht.range('H173:J213').options(pd.DataFrame).value
#Clean Index     
    SortAR = transbacklog.loc['Sort AR':'Sort Traditional',:].drop('Sort Traditional')
#    SortTradition = transbacklog[~transbacklog.loc[:,"FC"].isin(SortAR.loc[:,"FC"])]
    SortTradition = transbacklog[~transbacklog.FC.isin(SortAR.FC)]
#    fp = open("C:\\Yard_Backlog_Report.pdf","rb")
    SortAR.index = SortAR.index.fillna(" ")
    SortTradition.index = SortTradition.index.fillna(" ")
    transbacklog = pd.concat([SortAR, SortTradition])
#Formatting
#    for x in transbacklog.index:
#        x = x.ljust(20)
#    for x in transbacklog['Days Trans Backlog ']:
#        x = str(x)
#    
    msghtm = transbacklog.to_html()
    msghtm = msghtm.replace('<td>','<td style="text-align: right;">')


# load the file

    soup = BeautifulSoup(msghtm,"lxml")

# create new text
    tag = soup.new_tag("p")
    tag.string = """Hello all, Please find the Yard Backlog Report attached, summary below: """
# insert it into the document
    soup.body.insert_before(tag)
# create new text
    tag = soup.new_tag("p", style = "color:red;" )
    tag.string = """Note: Starting from Jan 15, 2018, the yard backlog report will not be attached with this email , you can access the report by clicking the link below. """
# insert it into the document
    soup.body.insert_before(tag)# create new text
    tag = soup.new_tag("p")
    tag.string = """https://Yard_Backlog_Report.pdf"""
# insert it into the document
    soup.body.insert_before(tag)


    body = MIMEMultipart('alternative')  
#    body.attach(MIMEText("""Hello All,
#                  
#    
#                        Please find the Yard Backlog Report attached, summary below:  \n""" ))
    body.attach(MIMEText(str(transbacklog),'plain'))
    body.attach(MIMEText(soup, 'html'))
#    body = MIMEText(fp.read())
#    fp.close()
    msg.attach(body)
    
    part = MIMEBase('application', "octet-stream")
    part.set_payload(open("CYard_Backlog_Report.pdf","rb").read())
    encoders.encode_base64(part)
    part.add_header('Content-Disposition', 'attachment; filename="Yard_Backlog_Report.pdf"')
    msg.attach(part)



    smtp = smtplib.SMTP('ballard.amazon.com',1587 )
    if isTls:
        smtp.starttls()
    smtp.login(send_from,password)
    for address in send_to:
        smtp.sendmail(send_from, address, msg.as_string())
    smtp.quit()

#For Windows Only
if time.localtime(os.path.getmtime("Cbgca.csv")).tm_hour == time.localtime(os.path.getmtime("C:\cu.csv")).tm_hour == datetime.datetime.now().hour:

   send_mail()
    
#try:
#    os.remove("C:Yard_Backlog_Report.pdf")
#except OSError:
#    pass
